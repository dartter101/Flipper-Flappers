**Project:** *Flipper & Flapper (Dolphin ID)*
  
**Group members:**
**Evan Lopaotsky Mehak Maqsood  Jamie Ching Man Leung**
   
**Abstract:**
  
Our kaggle project was to create a model that is capable of predicting individual dolphins by looking at images of dolphins, or more specifically their fins, and determining whether the dolphin was a new dolphin or an already previously recorded dolphin. The idea is much like fingerprinting criminals, when a crime is committed and a fingerprint found at the scene the offending fingerprint(s) are compared to the database to see of the criminal is already on file if they are not in the database then they would be put under the label of being a new print. Our approach was to use image Classification and Linear regression with a neural network to differentiate one dolphin from another, in doing so we would then be able to say whether an image that was tested was a new dolphin or a dolphin already on file. The results of our output could accurately tell if a dolphin was a new dolphin or a previously known dolphin.
    
**Introduction:** 

Our chosen Kaggle project was provided by HappyWhale, the project was to be able to differentiate one dolphin from another  by their dorsal fins. The idea was a lot like how humans can be identified by their fingerprints. Instead of using the loop whorl, and arches of human fingerprints to tell one human from another we will be looking at the shape, nicks scars and size of the dolphins fin to tell one dolphin from another
  
This information is very important because it will help researchers be able to save time, as the comparison process is done by hand over a long period. With the time saved the researchers will be able to take notes of trends or habits of particular dolphins, giving them an upper hand to be quick to be able to note when those individuals deviate from their normal behaviors. Being able to tell individuals apart can provide invaluable insight into the basic biology and it is highly relevant to science-based conservation.  Dolphins are important in determining the health of the ocean by serving as bioindicators for us. In allowing a faster smoother process for identifying dolphins researchers will be able to gain more accurate data on the state of the ocean climates, as well as help preserve the dolphin species, and better understand the current state of the oceans as well as how we can maintain the health of our world's oceans going into the future.
  
Our results can help inform researchers about whether a dolphin is a new dolphin or a previously known dolphin. This will contribute to helping ease the inspection of the world's oceans using dolphins as indicators helping keep track of new dolphins in the wild.
  
**Related Works:**
  
*Image recognition* was something that had our attention and we wanted to do something along those lines. After some research, a classic image recognition algorithm mainly includes key points for images to be compared through a dataset and learning algorithm as well as multi-classification network for identification. Our model has a similar method of classifying the dolphins by creating a key points for the images and then comparing the most likely similar images in the training set to train the model and test set through brute force search then use double network to further identify the dolphin speci on individual basis. It is somewhat corrimal to even compare our output to theirs. In the article they claimed something like a 90% success rate for identifying individuals while the best we could claim was better than coin flip odds determining if an individual was known or not.

**HappyWhale:** 
The HappyWhale competition on kaggle was our main inspiration behind choosing this project as we wanted to do something that was beneficial for the environment and it fit perfectly with our motto. The project was supposed to develop a model which matches the individual whales and dolphins by unique but rather subtle and visible characteristics of their natural marking- fins. The attention was particularly focused on the dorsal fins and the makings on it as well as lateral body views in image sets from a multi-species dataset built by 28 research institutions the submissions will suggest photo-ID solutions to identify whales and dolphins from each other. Following it closely our model is supposed to identify the individual dolphins from each other. Each dolphin has an ID that is related to that specific speci according to their dorsal fin and then the marking on their fins act as a human fingerprint which can help identify individual dolphins from each other.   
  
The HappyWhale projects used the EfficientNetV2-XL model with a DOLG head and ArcFace classifier which uses classification for their identification  and a single layered Network called SE-ResNeXt-50 pre-trained their data and then adding pipeline to gather the results, whereas Our model is supposed to use Classification and Linear Regression for identification adding features of the dolphins and linear regression to to predict the value of the model correctly and as accurately as possible. Once a speci of dolphin is identified we use the Neuron network to train the model to see if it's the same species and then another layer is added making it a multilayered network. In our second layer we added more features to the model so it can predict if it's a new individual of the same speci or an existing dolphin.
Happy Whale also used Arcface as one of the performing methods in this competition which uses Metric Learning, a method often used in the process of machine learning. It can use a series of observations to construct a corresponding metric function, so as to learn the distance or difference between data and effectively describe the similarity between samples. When the sample size is small, metric learning shows significant advantages in the accuracy and efficiency of processing classification tasks. Which is what we have for our data as well as when you compare to real world data, our data is comparatively smaller but here we took a different approach to scale our data towards our model.

**Data:**  
  
The data we are working with is mostly dolphin images, majorly images of dorsal fins with some side-body images as well. The images, ~65 GB,  were all provided by Happy Whale as part of the kaggle competition. Other data we worked with was mostly that of information about how identifying dolphins worked and the key features in identifying dolphins such notches, nicks, scars, shape, and size for the dorsal fin. We trained our model with the images from the dataset and resized the images to improve the performance and regulazie data.

**Methods:**
  
 Our original approach was to attempt to set up and run  a submission to a previous competition that was attempting to identify dolphins and whales and identify their speci. However we took a step ahead and using the Data science algorithms done in class decided to identify individual Dolphins based on their speci first and then their ID. the theoretical method to achieve this model was using classification to add features in the model to train it to see if the image was a dolphin and then tell the speci of the dolphin based on the individual features of each speci of dolphins and then using Linear Regression make it capable to predict the dolphin speci by looking at the picture and if given a new speci be able to identify it as a new individual. The hope was that if we managed to make it work for us that we could then go through detail by detail and determine what we could repurpose it to more suit what we needed it to do. This attempt was ultimately abandoned due to several factors including out of date code and collabs limitations on GPU. After a few hours we ran out of GPU on colab  and this slowed the process of trying to update and debug the code, after about a week of on and off trying to do this we came to the conclusion that since we weren't even trying to actual use the code as our project but rather to understand it and emulate some of the elements we thought would fit what we wanted. Fortunately this was not a complete waste of time, well it was for coding but not for information. While looking at the code we noticed several interesting elements that could be useful, more on this in the experiments and Conclusion sections. We believed this initial  step was the correct choice even though it ended up not working fully for us. We have limited knowledge on this subject and to see and play with working code that achieved a similar feat to what we desired would likely have allowed us to produce a far more accurate code then what would have been able to manage otherwise. Don't reinvent the wheel, rather  improve upon it, with that said it might be a good thing that we failed to make this work in a timely enough fashion to draw off of it for our project. Due to that failure we definitely gained a significant amount of understanding for some of the more minute basic details than we might have should we have managed to make this first attempt work for us.
  
Our next approach was similar to the cat and dogs problem for assignment 3 . We used the provided train.csv file, the file contained a line for each image provided in the training images as well as the species and individual id for the dolphin in the image, create arrays of each dolphins images then with python create a folder for each of those dolphins and filled it with their respective images. It was here we grew to appreciate just how much data we were dealing with, we were using the kaggle competition data and the images provided came to ~ 60 GB. WE realized that just trying to set up the folders we eat through all of our time or GPU provided by collab. So we moved on, we ran some code that made a dictionary key value pairing of the id for the dolphin and the number of images and picked 3 of the largest ids at random, a mistake that we realized later. With some fiddling to the code we got to a point where ~60 - 65% of the time it could accurately predict which dolphin we were looking at about 4 in 6. However when we went to test to discover new individuals it was all over the place, this is when we realized our mistake in choosing three randomly selected ids. We had managed to choose dolphin ids that belonged to different species so instead of comparing 3 different individuals we instead ended up comparing three species, much like adding a horse to the cat and dog, and while our species are much closer to one another than the cat dog horse variant it was still disappointing to realize that much of our success up until that moment likely stemmed from this species variation. After this we took a step back and more carefully chose our individuals, choosing three of the same species. After this change our accuracy of prediction dropped badly to about 45% of the time which meant we were worse than a coin flip at predicting which of the three dolphins we had an image of. Unfortunately we found that entering a dolphin of a different species occasionally gave wildly inaccurate results. This approach of using a neural network to solve our problem was not what we originally intended to, originally we planned to use decision trees however due to a combination of the few examples we found not working first try and low moral, due to having nothing to show for a week of effort, we decided that it would be best to get working with something we were at least somewhat familiar with and knew we had a working version.
  
Our final approach utilized what we had managed to do with the previous step and tried to take it one step further by actually being able to differentiate between individual dolphins. We were unfortunately not very good at differentiating between individuals but we could pick out new individuals that were not in the part of the test. With this small success and the lack of time we had to sadly buckle down and stop trying to progress out code and instead focus on other aspects of the project.  

**Experiments:**  
  
**Jax VS NUMPY:**  
Jax is a mathematical library similar to Numpy with an updated version of Autograd which became popular as a base framework to develop Machine Learning solutions. It can automatically differentiate between Python and NumPy code through a large subset of python’s features like loops, recursion, ifs and can take derivatives or derivatives which is especially useful in supervised learning which is mainly our project based on as it supports the reverse mode as well as the forward mode differentiation. The added benefit of using Jax in a supervised learning as opposed to NumPy is that,it uses XLA to compile and run your NumPy code of accelerators, like GPUs and TPUs which versatility of allowing to compile your own just-in-time python functions into a XLA- optimized kernels using one-function API which allows sophisticated algorithms and get maximal performance without leaving python. For our project, we first wrote the code in NumPy to try and test the model and its prediction to see how fast it loaded the data and made predictions and Later switched to Jax to see how it compared to the NumPy. Since one of the features of Jax was to speed up the Machine Learning pipelines without worrying about writing too much code. The ability of Jax to auto-compile code on GPU without any medication was seamless as once the code is written in NumPy the syntax is pretty similar to Numpy. We tested the NumPy code on our CPU for smaller data and later shipped the code without having to made ton of changes to GPU using Jax, instead the code was more concise when written in Jax and allowed multi-features with one function, for example arrays in Jax which we frequently used to get the images from the dataset to be passed into the training model. Jax's Array is multidimensional with the same array function used for 1d array or more. The Jax constructor allowed smooth flow of importing features and combining the Kers and Jax libraries. However, Jax made little difference while burning through our GPU as opposed to NumPy. Though it did save us a few seconds for the little data we were using which explains how jax can compile and run faster and save time as if it saves seconds over hundred pictures then if the data was in few thousands then the difference would be significantly larger.
	 
   **Minimum test data:**
     
We spent some time trying to determine the threshold for when a new dolphin could no longer be distinguished from  known dolphins. The lowest number we were somewhat successful with was in the low 70’s, when individuals with lower image counts than that were used it became impossible to differentiate between known and unknown with any reliability. We spent some time trying to come up with a solution on how to help with that, see the future part of the conclusion.

  
**Conclusion:**
  
Our results most simply was the ability to determine whether a dolphin was an already identified dolphin. Though we were able to use Classification and multilayers Neuron Network for our code for identification, including Linear Regression to predict a new individual dolphin was where we had the most trouble with. It was more difficult than we had hoped to identify one dolphin from another of the same species, a large part of this is likely due to photo counts. While species had large photo counts often in the thousands, individual dolphins had much smaller counts in the low 100 range of that, this almost certainly is why we struggled to determine differences between individuals as training requires a large dataset to compare and be able to predict.

If we were to attempt this in the future we would attempt to make the following improvements. First to find a better image manipulation then simply resizing it near the end we began playing with the idea of making the photos black and white but by that point we were concerned we would be unable to finish before the deadline. Other alternatives to help improve the accuracy of predicting between individuals would be to rotate the images, we are not entirely sure this would work but we hoped that by rotating the images that we could increase the accuracy of determining one individual form another, this idea was inspired by a previous kaggle competition that was trying to achieve a similar idea for whales. Another improvement would be to find a way to break the train.csv file into more manageable chunks, say a file for each species, and then run the model trainer off of those files rather than searching through the directories for this would save the absolutely stupendous amounts of time we lost training to move images around to create directories, more than once we lost several hours of time because the colab environment kicked us out mid move. Another improvement would be to increase the epochs we used since due to time and gpu constraints we often ran with only 10 to try the model, on the few attempts we did run with significantly greater epochs, 100, we did manage to get better accuracy.

